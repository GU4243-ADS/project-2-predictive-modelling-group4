---
title: "Project 2 - Example Main Script"
author: "Xiangyu Liu"
date: "February 2, 2018"
output:
  pdf_document: default
  html_document: default
---
## STEP0: Prepare and load the library
```{r}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}

if(!require("gbm")){
  install.packages("gbm")
}

if(!require("pbapply")){
  install.packages("pbapply")
}

library("EBImage")
library("gbm")
library("tidyverse")
```
##set the working derectory
```{r}
setwd("../doc") 
# Replace the above with your own path or manually set it in RStudio to where the main.rmd file is located. 
```
##set the directory for the training set and test set
```{r}
img_train_dir  <- "../data/pets/train/"  ##This is where I put the traing data

img_test_dir   <- "../data/pets/test/"  ##This is where I put the test data
```
##read the labels of traing data
```{r}
labels = read_csv(paste(img_train_dir, '../train_label.txt', sep=''), col_names = c('label'))

head(labels,10)
```
# There are 2000 images in the training set. Then we will read in all the images and store their dimensions in the `dat` matrix.

```{r}
n_files <- length(list.files(img_train_dir))
n_files
```

```{r}
dat <- matrix(NA, nrow = n_files, ncol = 3) 
imgs <- vector("list", n_files)

for(i in 1:n_files){
  img <- readImage(paste0(img_train_dir,  "pet", i, ".jpg"))
  imgs[[i]] <- img
  dat[i, 1:length(dim(img))] <- dim(img)
}
head(dat)
```

## get the general information of the images
```{r}
# How many B/W images?  All color.
table(dat[, 3])
# How many rows in each image?
table(dat[, 1])
```
##resize the image
```{r}
img_resized = pblapply(imgs, function(img) { resize(img, 128, 128) })
dim(img_resized[[1]])
```
##construct visual features
```{r}
feature <- function(img_dir, data_name, export=T){
  
  ### Construct process features for training/testing images
  ### Sample simple feature: Extract row average raw pixel values as features
  
  ### Input: a directory that contains images ready for processing
  ### Output: an .RData file contains processed features for the images
  
  ### load libraries
  library("EBImage")
  
  n_files <- length(list.files(img_dir))
  
  ### determine img dimensions
  img0 <-  readImage(paste0(img_dir, data_name, 1, ".jpg"))
  mat1 <- as.matrix(img0)
  n_r  <- nrow(img0)
  
  ### store vectorized pixel values of images
  dat <- data.frame(matrix(nrow = 2000, ncol = 1280))
  for(i in 1:n_files){
    img     <- readImage(paste0(img_dir, data_name, i, ".jpg"))
    mean    <- rowMeans(img)
    for( j in 1:(length(mean))){
      dat[i,j] <- mean[j]
    }
  }

  
  ### output constructed features
  if(export){
    save(dat, file = paste0("../output/feature_", data_name, ".RData"))
  }
  return(dat)
}
```

There is still some problem in this function - need to be revised.
```{r}
source("../lib/feature.R")
run.feature.train <- TRUE # process features for training set

run.feature.test  <- TRUE # process features for test set

tm_feature_train <- NA

if(run.feature.train){
  tm_feature_train <- system.time(dat_train <- feature(img_train_dir, data_name = "pet", export = TRUE))
}
tm_feature_train
dat_train
tm_feature_test <- NA
if(run.feature.test){
  tm_feature_test <- system.time(dat_test <- feature(img_test_dir, "test", 
                                                     data_name = "pets", export = TRUE))
}

```

